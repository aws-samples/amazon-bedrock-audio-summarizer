{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3814c18f-7060-48c9-8da4-e514ef0323b8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The purpose of this notebook is to give you a better understanding of how the infrastructure deployed by CDK transcribes a file and summarizes it, using S3, Transcribe, Lambda, and Bedrock. At the end of this notebook you will get back a transcription (as `json` and `txt`) and summarization (using Bedrock) of your audio file. \n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This notebook assumes that you have an AWS account, and sufficient IAM credentials to access Amazon S3, AWS Lambda, Amazon Transcribe, and Amazon Bedrock. It also assumes that you've already used the AWS CDK to deploy your project infrastructure. If you haven't done this yet, follow the instructions provided in [`README.md`](https://github.com/aws-samples/amazon-bedrock-audio-summarizer/blob/main/README.md).\n",
    "\n",
    "Note: The [summarizer Lambda function](/lambda/eventbridge-bedrock-inference/lambda_function.py) deployed by the CDK is hardcoded to use Anthropic's Claude 3 Sonnet LLM. You can [enable access to Claude 3](https://console.aws.amazon.com/bedrock/home?#/models) via the AWS Bedrock Console, or replace the model ID and invocation parameters inside the Lambda function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6a20d-89b7-4e2c-bc29-dc5cf261c620",
   "metadata": {},
   "source": [
    "## List S3 Buckets\n",
    "Start by installing `boto3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb400075-5845-4248-b3b3-51e28930a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abed0e5b-6855-4cb7-925b-672a91baecc1",
   "metadata": {},
   "source": [
    "Then retrieve all of the available S3 buckets in your account. You should have a bucket that looks something like this: `summarizerstack-summarizer...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51487a20-1409-403c-bd66-4f206b64c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bucket_name = ''\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "for bucket in buckets:\n",
    "    if bucket.startswith('summarizerstack-'):\n",
    "        bucket_name = bucket\n",
    "        print(f'Found bucket {bucket_name}')\n",
    "\n",
    "if bucket_name == '':\n",
    "    print('Summarizer bucket not found. Did you deploy the infrastructure with `cdk-deploy`?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861a54b-87dc-4aaf-9849-891c4076edfb",
   "metadata": {},
   "source": [
    "## Get folders\n",
    "\n",
    "Update the code block below with your S3 bucket. After running this block, you should see three folders: `processed`, `source`, and `transcription`. This ensures that the app was deployed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1bd81-917a-4a75-9fe3-4bb17b7d4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_folders = s3.list_objects_v2(Bucket=bucket_name, Delimiter='/')\n",
    "print(f'Folders in {bucket_name}:')\n",
    "for prefix in bucket_folders.get('CommonPrefixes', list()):\n",
    "    print('\\t - ' + prefix.get('Prefix', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff886a4-17ec-43a2-bcfe-d610cf705fa4",
   "metadata": {},
   "source": [
    "## Upload audio to S3\n",
    "\n",
    "Next, upload an audio file to your S3 bucket in the `source` folder. When complete, this will trigger a series of Lambdas to transcribe and summarize the audio. In the code blow below, add your audio file name. **Note**: This example assumes that audio is in the current working directory. \n",
    "\n",
    "Supported [media formats](https://docs.aws.amazon.com/transcribe/latest/dg/how-input.html#how-input-audio): AMR, FLAC, M4A, MP3, MP4, Ogg, WebM, WAV. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbccf18b-cff0-4bb3-8541-9fa90ced697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace with your audio file. This assumes the file is in the current working directory.\n",
    "audio_file_name = '<AUDIO_FILE>'   \n",
    "file_path = os.path.join(os.getcwd(), audio_file_name)\n",
    "\n",
    "# Upload the file to the S3 bucket\n",
    "object_name = 'source/' + audio_file_name\n",
    "with open(file_path, 'rb') as file:\n",
    "    s3.upload_fileobj(file, bucket_name, object_name)\n",
    "    print(f\"File '{file_path}' uploaded to '{bucket_name}/{object_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60c4dc-2ed7-423a-9602-64c0ce4bea51",
   "metadata": {},
   "source": [
    "## Monitor transcription status\n",
    "\n",
    "When an audio file is uploaded to the `source` folder, an S3 trigger invoked a [Lambda function](/lambda/s3-trigger-transcribe/lambda_function.py). That Lambda function created an Amazon Transcribe job\n",
    "\n",
    "The code block below is doing a few things: \n",
    "\n",
    "1. Checking for active transcriptions\n",
    "2. Assigning the latest transcription to `job_name`\n",
    "3. Monitoring the status of the transcription job\n",
    "\n",
    "Depending on the size of the audio file, jobs can take a few minutes.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f07781-b386-4d5d-bc4c-6c473c6c1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create a Transcribe client\n",
    "transcribe = boto3.client('transcribe')\n",
    "\n",
    "# List active transcription jobs\n",
    "try:\n",
    "    response = transcribe.list_transcription_jobs(\n",
    "        Status='IN_PROGRESS'\n",
    "    )\n",
    "    active_jobs = response['TranscriptionJobSummaries']\n",
    "\n",
    "    # Sort active jobs by creation time\n",
    "    active_jobs.sort(key=lambda job: job['CreationTime'], reverse=True)\n",
    "\n",
    "    # Print the list of active jobs\n",
    "    if active_jobs:\n",
    "        print(\"Active transcription jobs:\")\n",
    "        for job in active_jobs:\n",
    "            print(f\"- {job['TranscriptionJobName']} ({job['TranscriptionJobStatus']})\")\n",
    "        \n",
    "        # Assign the latest job name to job_name\n",
    "        job_name = active_jobs[0]['TranscriptionJobName']\n",
    "        print(f\"\\nThe latest transcription job is: {job_name}\\n\")\n",
    "    else:\n",
    "        print(\"No active transcription jobs found.\")\n",
    "        \n",
    "except transcribe.exceptions.BadRequestException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except transcribe.exceptions.InternalFailureException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except transcribe.exceptions.LimitExceededException as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "max_retries = 60  # Maximum number of retries\n",
    "retry_delay = 15  # Delay between retries (in seconds)\n",
    "\n",
    "# Monitor/poll for transcription status\n",
    "retries = 0\n",
    "while retries < max_retries:\n",
    "    try:\n",
    "        response = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        job_status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "        print(f\"Job status: {job_status}\")\n",
    "        \n",
    "        if job_status == 'COMPLETED':\n",
    "            transcription_file_uri = response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "            print(f\"Transcription file: {transcription_file_uri}\")\n",
    "            break\n",
    "        elif job_status == 'FAILED':\n",
    "            failure_reason = response['TranscriptionJob']['FailureReason']\n",
    "            print(f\"Job failed: {failure_reason}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Job is still in progress. Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "            retries += 1\n",
    "\n",
    "    except transcribe.exceptions.BadRequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except transcribe.exceptions.InternalFailureException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except transcribe.exceptions.LimitExceededException as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4268413a-6a10-47b3-96c0-04c2b1239157",
   "metadata": {},
   "source": [
    "## Retrieve the summary\n",
    "\n",
    "Last but not least, let's get the transcription summary. Amazon EventBridge was watching for any job named `summarizer-` to reach a `COMPLETED` state. When it found one, it kicked off a [Lambda function](/lambda/eventbridge-bedrock-inference/lambda_function.py) to format the transcription and create an inference request to Amazon Bedrock.\n",
    "\n",
    "The code block below is checking to see if there is a summary that matches the transcription job. If there is a match, the summary is printed below.\n",
    "\n",
    "**Note:** It may take a few seconds for the summarization job to appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd93d5-fde8-4b3e-b361-78157803944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'processed/'\n",
    "\n",
    "# Call the list_objects_v2 method with the Prefix parameter\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "summary_found = False\n",
    "while not summary_found:\n",
    "    for obj in response.get('Contents', []):\n",
    "        if job_name in obj['Key']:\n",
    "            summary_found = True\n",
    "            try:\n",
    "                # Get the object from S3\n",
    "                obj = s3.get_object(Bucket=bucket_name, Key=f'{prefix}{job_name}.txt')\n",
    "            \n",
    "                # Read the contents of the file\n",
    "                summary = obj['Body'].read().decode('utf-8')\n",
    "            \n",
    "                # Print the summary\n",
    "                print(summary)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "    if summary_found:\n",
    "        break  # Exit the outer loop if the summary is found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccfd9b-52df-437a-8d11-b322d0dbbe84",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "The last step is to clean up your project using the CDK CLI. Follow the instructions in our [`README.md`](https://github.com/aws-samples/amazon-bedrock-audio-summarizer/blob/main/README.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
